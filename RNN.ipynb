{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/joaogui1/tensorflow2_learning/runs/p3oxikz0\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
       "            in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import LSTM, SimpleRNN, Dropout\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import plotutil\n",
    "from plotutil import PlotCallback\n",
    "\n",
    "wandb.init()\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.repeated_predictions = False\n",
    "config.look_back = 20\n",
    "\n",
    "df = pd.read_csv('daily-min-temperatures.csv')\n",
    "data = df.Temp.astype('float32').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-config.look_back-1):\n",
    "        a = dataset[i:(i+config.look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + config.look_back])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(data) * 0.70)\n",
    "train = data[:split]\n",
    "test = data[split:]\n",
    "\n",
    "trainX, trainY = create_dataset(train)\n",
    "testX, testY = create_dataset(test)\n",
    "\n",
    "trainX = trainX[:, :, np.newaxis]\n",
    "testX = testX[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2534 samples, validate on 1074 samples\n",
      "Epoch 1/1000\n",
      "2534/2534 [==============================] - 23s 9ms/sample - loss: 9.9409 - mae: 9.9409 - val_loss: 10.5370 - val_mae: 10.5370\n",
      "Epoch 2/1000\n",
      "2534/2534 [==============================] - 23s 9ms/sample - loss: 9.9282 - mae: 9.9282 - val_loss: 10.5357 - val_mae: 10.5357\n",
      "Epoch 3/1000\n",
      "2534/2534 [==============================] - 24s 9ms/sample - loss: 9.9268 - mae: 9.9268 - val_loss: 10.5353 - val_mae: 10.5353\n",
      "Epoch 4/1000\n",
      "2534/2534 [==============================] - 23s 9ms/sample - loss: 9.9262 - mae: 9.9261 - val_loss: 10.5351 - val_mae: 10.5351\n",
      "Epoch 5/1000\n",
      "2534/2534 [==============================] - 23s 9ms/sample - loss: 9.9258 - mae: 9.9258 - val_loss: 10.5350 - val_mae: 10.5350\n",
      "Epoch 6/1000\n",
      "2534/2534 [==============================] - 28s 11ms/sample - loss: 9.9257 - mae: 9.9257 - val_loss: 10.5350 - val_mae: 10.5350\n",
      "Epoch 7/1000\n",
      "2534/2534 [==============================] - 29s 11ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5350 - val_mae: 10.5350\n",
      "Epoch 8/1000\n",
      "2534/2534 [==============================] - 33s 13ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5350 - val_mae: 10.5350\n",
      "Epoch 9/1000\n",
      "2534/2534 [==============================] - 28s 11ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5350 - val_mae: 10.5350\n",
      "Epoch 10/1000\n",
      "2534/2534 [==============================] - 24s 9ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5350 - val_mae: 10.5350\n",
      "Epoch 11/1000\n",
      "2534/2534 [==============================] - 26s 10ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5350 - val_mae: 10.5350\n",
      "Epoch 12/1000\n",
      "2534/2534 [==============================] - 28s 11ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5350 - val_mae: 10.5349\n",
      "Epoch 13/1000\n",
      "2534/2534 [==============================] - 20s 8ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 14/1000\n",
      "2534/2534 [==============================] - 27s 11ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 15/1000\n",
      "2534/2534 [==============================] - 33s 13ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 16/1000\n",
      "2534/2534 [==============================] - 29s 11ms/sample - loss: 9.9256 - mae: 9.9255 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 17/1000\n",
      "2534/2534 [==============================] - 32s 13ms/sample - loss: 9.9256 - mae: 9.9255 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 18/1000\n",
      "2534/2534 [==============================] - 34s 13ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 19/1000\n",
      "2534/2534 [==============================] - 30s 12ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 20/1000\n",
      "2534/2534 [==============================] - 25s 10ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 21/1000\n",
      "2534/2534 [==============================] - 29s 11ms/sample - loss: 9.9256 - mae: 9.9255 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 22/1000\n",
      "2534/2534 [==============================] - 32s 13ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 23/1000\n",
      "2534/2534 [==============================] - 32s 13ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 24/1000\n",
      "2534/2534 [==============================] - 34s 13ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 25/1000\n",
      "2534/2534 [==============================] - 33s 13ms/sample - loss: 9.9256 - mae: 9.9256 - val_loss: 10.5349 - val_mae: 10.5349\n",
      "Epoch 26/1000\n",
      " 157/2534 [>.............................] - ETA: 18s - loss: 10.1861 - mae: 10.1861"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(5, input_shape=(config.look_back,1 )))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae'])\n",
    "model.fit(trainX, trainY, epochs=1000, batch_size=1, validation_data=(testX, testY),  callbacks=[WandbCallback(), PlotCallback(trainX, trainY, testX, testY, config.look_back, config.repeated_predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
