{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(x_train, x_test, noise_factor=1.0):\n",
    "    # Function to add some random noise\n",
    "    x_train_noisy = x_train + np.random.normal(loc=0.0, scale=noise_factor, size=x_train.shape) \n",
    "    x_test_noisy = x_test + np.random.normal(loc=0.0, scale=noise_factor, size=x_test.shape) \n",
    "    \n",
    "    x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "    x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
    "    return x_train_noisy, x_test_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(x_train_noisy, x_test_noisy) = add_noise(x_train, x_test)\n",
    "img_width = x_train.shape[1]\n",
    "img_height = x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Flatten(input_shape=(img_width, img_height)))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(img_width*img_height, activation=\"sigmoid\"))\n",
    "model.add(Reshape((img_width, img_height)))\n",
    "model.compile(loss='mse', optimizer='adam',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: 0.0470 - mse: 0.0470 - val_loss: 0.0388 - val_mse: 0.0388\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 11s 190us/sample - loss: 0.0375 - mse: 0.0375 - val_loss: 0.0364 - val_mse: 0.0364\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 12s 195us/sample - loss: 0.0358 - mse: 0.0358 - val_loss: 0.0355 - val_mse: 0.0355\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 9s 143us/sample - loss: 0.0347 - mse: 0.0347 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 9s 157us/sample - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0343 - mse: 0.0343 - val_loss: 0.0346 - val_mse: 0.0346\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 9s 158us/sample - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 11s 189us/sample - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 13s 216us/sample - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0340 - val_mse: 0.0340\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 12s 198us/sample - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 12s 201us/sample - loss: 0.0334 - mse: 0.0334 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 12s 202us/sample - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 13s 212us/sample - loss: 0.0332 - mse: 0.0332 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 13s 211us/sample - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 12s 198us/sample - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 12s 198us/sample - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 12s 200us/sample - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 13s 208us/sample - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 13s 215us/sample - loss: 0.0329 - mse: 0.0329 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 10s 169us/sample - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0334 - val_mse: 0.0334\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 11s 188us/sample - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0328 - mse: 0.0328 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 11s 181us/sample - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 8s 129us/sample - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 9s 152us/sample - loss: 0.0326 - mse: 0.0326 - val_loss: 0.0336 - val_mse: 0.0336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4752a0e978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_noisy, x_train, epochs=30, validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy = x_train_noisy.reshape(-1, 28, 28, 1)\n",
    "x_test_noisy = x_test_noisy.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(32, 3, activation='relu', padding='same', input_shape=(img_width, img_height, 1)))\n",
    "model.add(Conv2D(32, 3, strides=2, activation='relu', padding='same'))\n",
    "model.add(Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same'))\n",
    "model.add(Conv2DTranspose(1, 3, activation='relu', padding='same'))\n",
    "model.compile(loss='mse', optimizer='adam',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 48s 792us/sample - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0278 - val_mse: 0.0278\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 53s 880us/sample - loss: 0.0279 - mse: 0.0279 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 76s 1ms/sample - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 73s 1ms/sample - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 58s 972us/sample - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: 0.0266 - mse: 0.0266 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 54s 908us/sample - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 60s 995us/sample - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 52s 859us/sample - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 60s 1ms/sample - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0263 - val_mse: 0.0263\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 51s 855us/sample - loss: 0.0263 - mse: 0.0263 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 46s 773us/sample - loss: 0.0262 - mse: 0.0262 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 47s 776us/sample - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 50s 836us/sample - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 48s 808us/sample - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 48s 793us/sample - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 55s 912us/sample - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 52s 865us/sample - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 45s 750us/sample - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 50s 831us/sample - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 43s 724us/sample - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 59s 988us/sample - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 63s 1ms/sample - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 64s 1ms/sample - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 63s 1ms/sample - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0257 - val_mse: 0.0257\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 59s 978us/sample - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0258 - val_mse: 0.0258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f46e4162390>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_noisy, x_train, epochs=30, validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f469eecaa58>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(x_test_noisy[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f469ed6e198>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(x_test_noisy[0].reshape(1, 28, 28, 1))\n",
    "plt.imshow(prediction.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f46e4337780>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
