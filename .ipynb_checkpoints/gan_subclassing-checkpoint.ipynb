{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gd6BCUIt_sZx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQqC0yMo39eD"
   },
   "outputs": [],
   "source": [
    "class Generator(keras.Model):\n",
    "    def __init__(self, input_dim=100, output_dim=784, name=\"Generator\", **kwargs):\n",
    "        super(Generator, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.hidden = list()\n",
    "        self.hidden.append(Dense(units=256,input_dim=input_dim, activation=tf.nn.leaky_relu,  name='generator_input'))\n",
    "        self.hidden.append(Dense(units=512, activation=tf.nn.leaky_relu))\n",
    "        self.hidden.append(Dense(units=1024, activation=tf.nn.leaky_relu))\n",
    "        self.output_layer = Dense(units=output_dim, activation='tanh', name='generator_output')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.hidden[0](inputs)\n",
    "        for layer in self.hidden[1:]:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    def generate_noise(self,batch_size, random_noise_size):\n",
    "        return np.random.uniform(-1,1, size = (batch_size, random_noise_size))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "\n",
    "def generator_objective(dx_of_gx):\n",
    "    # Labels are true here because generator thinks he produces real images. \n",
    "    return cross_entropy(tf.ones_like(dx_of_gx), dx_of_gx) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CItS4LMM78jq"
   },
   "outputs": [],
   "source": [
    "class Discriminator(keras.layers.Layer):\n",
    "    def __init__(self, input_dim=784, name=\"Discriminator\", **kwargs):\n",
    "        super(Discriminator, self).__init__(name=name, **kwargs)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.hidden = list()\n",
    "        self.hidden.append(Dense(units=1024,input_dim=input_dim, activation=tf.nn.leaky_relu,  name='discriminator_input'))\n",
    "        self.hidden.append(Dropout(0.2))\n",
    "        self.hidden.append(Dense(units=512, activation=tf.nn.leaky_relu))\n",
    "        self.hidden.append(Dropout(0.2))\n",
    "        self.hidden.append(Dense(units=256, activation=tf.nn.leaky_relu))\n",
    "        self.output_layer = Dense(units=1, activation='sigmoid', name='discriminator_output')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.hidden[0](inputs)\n",
    "        for layer in self.hidden[1:]:\n",
    "          x = layer(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_objective(d_x, g_z, smoothing_factor = 0.9):\n",
    "    \"\"\"\n",
    "    d_x = real output\n",
    "    g_z = fake output\n",
    "    \"\"\"\n",
    "    real_loss = cross_entropy(tf.ones_like(d_x) * smoothing_factor, d_x) # If we feed the discriminator with real images, we assume they all are the right pictures --> Because of that label == 1\n",
    "    fake_loss = cross_entropy(tf.zeros_like(g_z), g_z) # Each noise we feed in are fakes image --> Because of that labels are 0. \n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygTR0-lu9QXS"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, input_dim=100, latent_dim=784, name=\"GAN\", **kwargs):\n",
    "        super(GAN, self).__init__(name=name, **kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.G = Generator(latent_dim, input_dim)\n",
    "        self.D = Discriminator(input_dim)\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.G(input)\n",
    "        x = tf.concat([x, input[1]])\n",
    "        x = self.D(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMK-oa2g6g7c"
   },
   "outputs": [],
   "source": [
    "class GANback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.D.trainable = !self.model.D.trainable\n",
    "callback = GANback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpzsU55f8D2e"
   },
   "outputs": [],
   "source": [
    "(X, _), (X_test, _) = mnist.load_data()\n",
    "X = (X.astype(np.float32) - 127.5)/127.5\n",
    "X = X.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hc6F6UUM8c6a"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 60000\n",
    "EPOCHES = 300\n",
    "OUTPUT_DIR = \"img\"\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(X.reshape(X.shape[0],784)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "generator_optimizer = keras.optimizers.RMSprop()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "E9qsuyOm8Hdo",
    "outputId": "90766fa0-e267-487e-c53b-c6cee1bb59c8"
   },
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def training_step(generator: Discriminator, discriminator: Discriminator, images:np.ndarray , k:int =1, batch_size = 32):\n",
    "    for _ in range(k):\n",
    "         with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            noise = generator.generate_noise(batch_size, 100)\n",
    "            g_z = generator(noise)\n",
    "            d_x_true = discriminator(images) # Trainable?\n",
    "            d_x_fake = discriminator(g_z) # dx_of_gx\n",
    "\n",
    "            discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n",
    "            # Adjusting Gradient of Discriminator\n",
    "            gradients_of_discriminator = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables)) # Takes a list of gradient and variables pairs\n",
    "            \n",
    "              \n",
    "            generator_loss = generator_objective(d_x_fake)\n",
    "            # Adjusting Gradient of Generator\n",
    "            gradients_of_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataset, epoches):\n",
    "    for epoch in range(epoches):\n",
    "        for batch in dataset: \n",
    "            training_step(generator, discriminator, batch ,batch_size = BATCH_SIZE, k = 1)\n",
    "            \n",
    "        ## After ith epoch plot image \n",
    "        if (epoch % 50) == 0: \n",
    "            fake_image = tf.reshape(generator(seed), shape = (28,28))\n",
    "            print(f\"{epoch}/{epoches} epoches\")\n",
    "            #plt.imshow(fake_image, cmap = \"gray\")\n",
    "            plt.imsave(\"{OUTPUT_DIR}/{epoch}.png\".format(OUTPUT_DIR,epoch),fake_image, cmap = \"gray\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gan_subclassing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
